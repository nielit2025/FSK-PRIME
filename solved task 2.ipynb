{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L982FdumDCVn"
      },
      "source": [
        "# Task 2: Data Preprocessing for Machine Learning – AI Bootcamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO0AAR2ULftH"
      },
      "source": [
        "Download Titanic Dataset here: https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\n",
        "\n",
        "#### About this file\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk9AwRFXDO6n"
      },
      "source": [
        "## Section 1: Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG2LLFb4DSrf"
      },
      "source": [
        "### **Task 1**: Load and Inspect a Dataset\n",
        "\n",
        "*Instruction*: Load the `titanic.csv` dataset and display the first 5 rows. Show basic info and describe statistics of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G6YtbgenDSWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe21e16-d96b-4ae7-bdd7-49cb19d1408b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 887 entries, 0 to 886\n",
            "Data columns (total 8 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Survived                 887 non-null    int64  \n",
            " 1   Pclass                   887 non-null    int64  \n",
            " 2   Name                     887 non-null    object \n",
            " 3   Sex                      887 non-null    object \n",
            " 4   Age                      887 non-null    float64\n",
            " 5   Siblings/Spouses Aboard  887 non-null    int64  \n",
            " 6   Parents/Children Aboard  887 non-null    int64  \n",
            " 7   Fare                     887 non-null    float64\n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 55.6+ KB\n",
            "None\n",
            "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
            "count  887.000000  887.000000  887.000000               887.000000   \n",
            "mean     0.385569    2.305524   29.471443                 0.525366   \n",
            "std      0.487004    0.836662   14.121908                 1.104669   \n",
            "min      0.000000    1.000000    0.420000                 0.000000   \n",
            "25%      0.000000    2.000000   20.250000                 0.000000   \n",
            "50%      0.000000    3.000000   28.000000                 0.000000   \n",
            "75%      1.000000    3.000000   38.000000                 1.000000   \n",
            "max      1.000000    3.000000   80.000000                 8.000000   \n",
            "\n",
            "       Parents/Children Aboard       Fare  \n",
            "count               887.000000  887.00000  \n",
            "mean                  0.383315   32.30542  \n",
            "std                   0.807466   49.78204  \n",
            "min                   0.000000    0.00000  \n",
            "25%                   0.000000    7.92500  \n",
            "50%                   0.000000   14.45420  \n",
            "75%                   0.000000   31.13750  \n",
            "max                   6.000000  512.32920  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CKwCBtDzRL"
      },
      "source": [
        "## Section 2: Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh1W_9m5DuzF"
      },
      "source": [
        "### **Task 2**: Identify and Handle Missing Data\n",
        "\n",
        "*Instruction*:\n",
        "\n",
        "\n",
        "\n",
        "*   Display the number of missing values per column.\n",
        "*   Fill missing `Age` values with the median.\n",
        "*   Drop the `Cabin` column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQTsWR6GDn6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3731db-4960-486a-e9e9-f1824b9ac4ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "Survived                   0\n",
            "Pclass                     0\n",
            "Name                       0\n",
            "Sex                        0\n",
            "Age                        0\n",
            "Siblings/Spouses Aboard    0\n",
            "Parents/Children Aboard    0\n",
            "Fare                       0\n",
            "dtype: int64\n",
            "\n",
            "Updated DataFrame:\n",
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-883da2ca3a79>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Display the number of missing values per column\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Fill missing Age values with the median\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "\n",
        "# Drop the Cabin column if it exists\n",
        "if 'Cabin' in df.columns:\n",
        "    df.drop(columns=['Cabin'], inplace=True)\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(\"\\nUpdated DataFrame:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVV1BgZvEE3a"
      },
      "source": [
        "## Section 3: Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUK7Z7LEIr4"
      },
      "source": [
        "*italicized text*### **Task 3**: Convert Categorical to Numeric\n",
        "\n",
        "*Instruction*: Convert `Sex` and `Embarked` columns to numeric using:\n",
        "\n",
        "\n",
        "*   Label Encoding for `Sex`\n",
        "*   One-Hot Encoding for `Embarked`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52abe5d1-7bce-4157-b1c9-68d467b91ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial DataFrame:\n",
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "\n",
            "Columns in DataFrame:\n",
            "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard',\n",
            "       'Parents/Children Aboard', 'Fare'],\n",
            "      dtype='object')\n",
            "The 'Embarked' column is not found in the DataFrame.\n",
            "\n",
            "Updated DataFrame with Encoded Features:\n",
            "   Survived  Pclass                                               Name  Sex  \\\n",
            "0         0       3                             Mr. Owen Harris Braund    1   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...    0   \n",
            "2         1       3                              Miss. Laina Heikkinen    0   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle    0   \n",
            "4         0       3                            Mr. William Henry Allen    1   \n",
            "\n",
            "    Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0  22.0                        1                        0   7.2500  \n",
            "1  38.0                        1                        0  71.2833  \n",
            "2  26.0                        0                        0   7.9250  \n",
            "3  35.0                        1                        0  53.1000  \n",
            "4  35.0                        0                        0   8.0500  \n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Display the initial DataFrame and the column names\n",
        "print(\"Initial DataFrame:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns in DataFrame:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Task 3: Convert Categorical to Numeric\n",
        "\n",
        "# Step 1: Check and Label Encoding for the 'Sex' column\n",
        "if 'Sex' in df.columns:\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
        "else:\n",
        "    print(\"The 'Sex' column is not found in the DataFrame.\")\n",
        "\n",
        "# Step 2: One-Hot Encoding for the 'Embarked' column\n",
        "if 'Embarked' in df.columns:\n",
        "    # Using pd.get_dummies for One-Hot Encoding\n",
        "    embarked_dummies = pd.get_dummies(df['Embarked'], prefix='Embarked', drop_first=True)\n",
        "    df = pd.concat([df, embarked_dummies], axis=1)\n",
        "\n",
        "    # Drop the original 'Embarked' column as it's now encoded\n",
        "    df.drop(columns=['Embarked'], inplace=True)\n",
        "else:\n",
        "    print(\"The 'Embarked' column is not found in the DataFrame.\")\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(\"\\nUpdated DataFrame with Encoded Features:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNO0DPi3EpgF"
      },
      "source": [
        "## Section 4: Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W74DNGaJEtdj"
      },
      "source": [
        "### **Task 4**: Scale Numerical Features\n",
        "\n",
        "*Instruction*: Use StandardScaler to scale the Age and Fare columns.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM8iWEAXEOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a346d30-00e8-44aa-eb71-e937bf140938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial DataFrame:\n",
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "\n",
            "Updated DataFrame after scaling:\n",
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex       Age  Siblings/Spouses Aboard  Parents/Children Aboard  \\\n",
            "0    male -0.529366                        1                        0   \n",
            "1  female  0.604265                        1                        0   \n",
            "2  female -0.245958                        0                        0   \n",
            "3  female  0.391709                        1                        0   \n",
            "4    male  0.391709                        0                        0   \n",
            "\n",
            "       Fare  \n",
            "0 -0.503586  \n",
            "1  0.783412  \n",
            "2 -0.490020  \n",
            "3  0.417948  \n",
            "4 -0.487507  \n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Step 3: Display the initial DataFrame (optional)\n",
        "print(\"Initial DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 4: Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Step 5: Select the columns 'Age' and 'Fare' to be scaled\n",
        "columns_to_scale = ['Age', 'Fare']\n",
        "\n",
        "# Step 6: Check if columns exist in the DataFrame\n",
        "for column in columns_to_scale:\n",
        "    if column not in df.columns:\n",
        "        print(f\"Warning: '{column}' column is not found in the DataFrame.\")\n",
        "        # You can choose to continue or break here based on your needs\n",
        "\n",
        "# Step 7: Fit and transform the selected columns if they exist\n",
        "if all(column in df.columns for column in columns_to_scale):\n",
        "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
        "\n",
        "# Step 8: Display the updated DataFrame after scaling\n",
        "print(\"\\nUpdated DataFrame after scaling:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFxPFagsE9mS"
      },
      "source": [
        "## Section 5: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZwIOzHXFD1a"
      },
      "source": [
        "### **Task 5**: Build Preprocessing Pipeline\n",
        "\n",
        "*Instruction*: Using `ColumnTransformer` and `Pipeline` from `sklearn`, build a pipeline that:\n",
        "\n",
        "\n",
        "\n",
        "*   Imputes missing values\n",
        "*   Scales numeric data\n",
        "*   Encodes categorical data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpUFTR1JFDWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "d9e2032d-8db0-4092-938b-ae5dd919a13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial DataFrame:\n",
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "\n",
            "Columns in DataFrame:\n",
            "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard',\n",
            "       'Parents/Children Aboard', 'Fare'],\n",
            "      dtype='object')\n",
            "Warning: 'Embarked' column is not found in the DataFrame.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Embarked'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1c868c28a9ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Step 8: Fit and transform the data using the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Extract features only for processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Select features for processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Embarked'] not in index\""
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Display initial DataFrame\n",
        "print(\"Initial DataFrame:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns in DataFrame:\")\n",
        "print(df.columns)  # Check the available columns\n",
        "\n",
        "# Step 3: Define the numeric and categorical features\n",
        "numeric_features = ['Age', 'Fare']  # Numeric columns to scale\n",
        "categorical_features = ['Sex', 'Embarked']  # Categorical columns to encode\n",
        "\n",
        "# Make sure these columns exist in the DataFrame\n",
        "for feature in numeric_features + categorical_features:\n",
        "    if feature not in df.columns:\n",
        "        print(f\"Warning: '{feature}' column is not found in the DataFrame.\")\n",
        "\n",
        "# Step 4: Create the numeric transformer\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
        "    ('scaler', StandardScaler())  # Scale numeric features\n",
        "])\n",
        "\n",
        "# Step 5: Create the categorical transformer\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
        "])\n",
        "\n",
        "# Step 6: Combine transformers into a single column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),  # Apply numeric transformer\n",
        "        ('cat', categorical_transformer, categorical_features)  # Apply categorical transformer\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 7: Create the final pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor)  # This pipeline transforms the data\n",
        "])\n",
        "\n",
        "# Step 8: Fit and transform the data using the pipeline\n",
        "# Extract features only for processing\n",
        "X = df[numeric_features + categorical_features]  # Select features for processing\n",
        "X_transformed = pipeline.fit_transform(X)\n",
        "\n",
        "# Step 9: Display the shape of the transformed data\n",
        "print(\"\\nTransformed Data Shape:\", X_transformed.shape)\n",
        "\n",
        "# Step 10: Create a DataFrame from the transformed data for better readability\n",
        "# Get feature names after one-hot encoding to label the DataFrame\n",
        "ohe_feature_names = pipeline.named_steps['preprocessor']\\\n",
        "    .transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
        "column_names = numeric_features + list(ohe_feature_names)\n",
        "\n",
        "# Create a DataFrame with the transformed data\n",
        "processed_df = pd.DataFrame(X_transformed, columns=column_names)\n",
        "\n",
        "# Step 11: Print the processed data\n",
        "print(\"\\nProcessed Data:\")\n",
        "print(processed_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OY1jI5IaIB"
      },
      "source": [
        "## Section 6: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBCcr3RIi-8"
      },
      "source": [
        "### **Task 6**: Create a New Feature\n",
        "\n",
        "*Instruction*: Create a new feature `FamilySize` = `SibSp` + `Parch` + 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSza6VScIakN"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Step 3: Display the initial DataFrame and columns (optional)\n",
        "print(\"Initial DataFrame:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns in DataFrame:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Step 4: Create the new feature 'FamilySize'\n",
        "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "\n",
        "# Step 5: Define the numeric and categorical features\n",
        "# Include the new 'FamilySize' feature in the numeric features list\n",
        "numeric_features = ['Age', 'Fare', 'FamilySize']  # Numeric columns to scale\n",
        "categorical_features = ['Sex', 'Embarked']  # Categorical columns to encode\n",
        "\n",
        "# Step 6: Create the numeric transformer\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
        "    ('scaler', StandardScaler())  # Scale numeric features\n",
        "])\n",
        "\n",
        "# Step 7: Create the categorical transformer\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
        "])\n",
        "\n",
        "# Step 8: Combine transformers into a single column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),  # Apply numeric transformer\n",
        "        ('cat', categorical_transformer, categorical_features)  # Apply categorical transformer\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 9: Create the final pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor)  # This pipeline transforms the data\n",
        "])\n",
        "\n",
        "# Step 10: Fit and transform the data using the pipeline\n",
        "# Extract features only for processing\n",
        "X = df[numeric_features + categorical_features]  # Select features for processing\n",
        "X_transformed = pipeline.fit_transform(X)\n",
        "\n",
        "# Step 11: Display the shape of the transformed data\n",
        "print(\"\\nTransformed Data Shape:\", X_transformed.shape)\n",
        "\n",
        "# Step 12: Create a DataFrame from the transformed data for better readability\n",
        "# Get feature names after one-hot encoding to label the DataFrame\n",
        "ohe_feature_names = pipeline.named_steps['preprocessor'] \\\n",
        "    .transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
        "column_names = numeric_features + list(ohe_feature_names)\n",
        "\n",
        "# Create a DataFrame with the transformed data\n",
        "processed_df = pd.DataFrame(X_transformed, columns=column_names)\n",
        "\n",
        "# Step 13: Print the processed data\n",
        "print(\"\\nProcessed Data:\")\n",
        "print(processed_df.head())"
      ],
      "metadata": {
        "id": "33DiKxOHGAb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "outputId": "013bdc8a-60ff-4b96-e741-dfe40d8d6eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial DataFrame:\n",
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "\n",
            "Columns in DataFrame:\n",
            "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard',\n",
            "       'Parents/Children Aboard', 'Fare'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'SibSp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'SibSp'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8d5200a5d6c5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Step 4: Create the new feature 'FamilySize'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FamilySize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SibSp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Parch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Step 5: Define the numeric and categorical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'SibSp'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}