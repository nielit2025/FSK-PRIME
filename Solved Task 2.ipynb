{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L982FdumDCVn"
      },
      "source": [
        "# Task 2: Data Preprocessing for Machine Learning – AI Bootcamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EEWt7WNF5kP"
      },
      "source": [
        "Download Titanic Dataset here: https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\n",
        "\n",
        "#### About this file\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk9AwRFXDO6n"
      },
      "source": [
        "## Section 1: Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG2LLFb4DSrf"
      },
      "source": [
        "### **Task 1**: Load and Inspect a Dataset\n",
        "\n",
        "*Instruction*: Load the `titanic.csv` dataset and display the first 5 rows. Show basic info and describe statistics of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6YtbgenDSWH",
        "outputId": "3f28bd21-d249-45ea-a452-f01e7f704a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 887 entries, 0 to 886\n",
            "Data columns (total 8 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Survived                 887 non-null    int64  \n",
            " 1   Pclass                   887 non-null    int64  \n",
            " 2   Name                     887 non-null    object \n",
            " 3   Sex                      887 non-null    object \n",
            " 4   Age                      887 non-null    float64\n",
            " 5   Siblings/Spouses Aboard  887 non-null    int64  \n",
            " 6   Parents/Children Aboard  887 non-null    int64  \n",
            " 7   Fare                     887 non-null    float64\n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 55.6+ KB\n",
            "None\n",
            "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
            "count  887.000000  887.000000  887.000000               887.000000   \n",
            "mean     0.385569    2.305524   29.471443                 0.525366   \n",
            "std      0.487004    0.836662   14.121908                 1.104669   \n",
            "min      0.000000    1.000000    0.420000                 0.000000   \n",
            "25%      0.000000    2.000000   20.250000                 0.000000   \n",
            "50%      0.000000    3.000000   28.000000                 0.000000   \n",
            "75%      1.000000    3.000000   38.000000                 1.000000   \n",
            "max      1.000000    3.000000   80.000000                 8.000000   \n",
            "\n",
            "       Parents/Children Aboard       Fare  \n",
            "count               887.000000  887.00000  \n",
            "mean                  0.383315   32.30542  \n",
            "std                   0.807466   49.78204  \n",
            "min                   0.000000    0.00000  \n",
            "25%                   0.000000    7.92500  \n",
            "50%                   0.000000   14.45420  \n",
            "75%                   0.000000   31.13750  \n",
            "max                   6.000000  512.32920  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CKwCBtDzRL"
      },
      "source": [
        "## Section 2: Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh1W_9m5DuzF"
      },
      "source": [
        "### **Task 2**: Identify and Handle Missing Data\n",
        "\n",
        "*Instruction*:\n",
        "\n",
        "\n",
        "\n",
        "*   Display the number of missing values per column.\n",
        "*   Fill missing `Age` values with the median.\n",
        "*   Drop the second row in the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SQTsWR6GDn6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911ca5bf-6d03-4b28-b336-9b9cbdceb811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "Name    0\n",
            "Age     1\n",
            "City    1\n",
            "dtype: int64\n",
            "\n",
            "DataFrame after handling missing data:\n",
            "      Name   Age         City\n",
            "0    Alice  25.0     New York\n",
            "2  Charlie  30.0  Los Angeles\n",
            "3    David  22.0      Chicago\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-098efe7af9b0>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(median_age, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample DataFrame with missing values\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, np.nan, 30, 22],\n",
        "    'City': ['New York', np.nan, 'Los Angeles', 'Chicago']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Display the number of missing values per column\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# 2. Fill missing Age values with the median\n",
        "median_age = df['Age'].median()\n",
        "df['Age'].fillna(median_age, inplace=True)\n",
        "\n",
        "# 3. Drop the second row in the dataset\n",
        "df.drop(index=1, inplace=True)\n",
        "\n",
        "# Display the DataFrame after handling missing data\n",
        "print(\"\\nDataFrame after handling missing data:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVV1BgZvEE3a"
      },
      "source": [
        "## Section 3: Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUK7Z7LEIr4"
      },
      "source": [
        "### **Task 3**: Convert Categorical to Numeric\n",
        "\n",
        "*Instruction*: Convert `Sex` and `Pclass` columns to numeric using:\n",
        "\n",
        "\n",
        "*   Label Encoding for `Sex`\n",
        "*   One-Hot Encoding for `Pclass`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3f1b79-cb0a-4cb5-8f1f-25e67eab1e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      Name     Sex  Pclass\n",
            "0    Alice  female       1\n",
            "1      Bob    male       2\n",
            "2  Charlie    male       1\n",
            "3    David  female       3\n",
            "\n",
            "DataFrame after converting categorical to numeric:\n",
            "      Name  Sex  Pclass_2  Pclass_3\n",
            "0    Alice    0     False     False\n",
            "1      Bob    1      True     False\n",
            "2  Charlie    1     False     False\n",
            "3    David    0     False      True\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Your code here\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Sex': ['female', 'male', 'male', 'female'],\n",
        "    'Pclass': [1, 2, 1, 3],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# 1. Label Encoding for 'Sex'\n",
        "df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
        "\n",
        "# 2. One-Hot Encoding for 'Pclass'\n",
        "df = pd.get_dummies(df, columns=['Pclass'], prefix='Pclass', drop_first=True)\n",
        "\n",
        "# Display the modified DataFrame\n",
        "print(\"\\nDataFrame after converting categorical to numeric:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNO0DPi3EpgF"
      },
      "source": [
        "## Section 4: Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W74DNGaJEtdj"
      },
      "source": [
        "### **Task 4**: Scale Numerical Features\n",
        "\n",
        "*Instruction*: Use StandardScaler to scale the Age and Fare columns.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aM8iWEAXEOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e092cd15-5c6c-46a3-f441-380fa9119458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      Name  Age  Fare\n",
            "0    Alice   25   100\n",
            "1      Bob   30   150\n",
            "2  Charlie   22    75\n",
            "3    David   35   200\n",
            "\n",
            "DataFrame after scaling Age and Fare:\n",
            "      Name       Age      Fare\n",
            "0    Alice -0.606092 -0.650945\n",
            "1      Bob  0.404061  0.390567\n",
            "2  Charlie -1.212183 -1.171700\n",
            "3    David  1.414214  1.432078\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Your code here\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample DataFrame with Age and Fare columns\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 30, 22, 35],\n",
        "    'Fare': [100, 150, 75, 200]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Instantiate the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale the Age and Fare columns\n",
        "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "# Display the DataFrame after scaling\n",
        "print(\"\\nDataFrame after scaling Age and Fare:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFxPFagsE9mS"
      },
      "source": [
        "## Section 5: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZwIOzHXFD1a"
      },
      "source": [
        "### **Task 5**: Build Preprocessing Pipeline\n",
        "\n",
        "*Instruction*: Using `ColumnTransformer` and `Pipeline` from `sklearn`, build a pipeline that:\n",
        "\n",
        "\n",
        "\n",
        "*   Imputes missing values\n",
        "*   Scales numeric data\n",
        "*   Encodes categorical data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VpUFTR1JFDWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3662625f-8c08-4685-d72a-b2a8cc146435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed DataFrame:\n",
            "   Age_scaled  Fare_scaled  Sex_female  Sex_male  Sex_missing  Pclass_1  \\\n",
            "0   -0.260820    -0.278543         1.0       0.0          0.0       1.0   \n",
            "1    0.000000     0.649934         0.0       1.0          0.0       0.0   \n",
            "2    1.695332    -0.742781         0.0       1.0          0.0       1.0   \n",
            "3   -1.434511     1.578410         1.0       0.0          0.0       0.0   \n",
            "4    0.000000    -1.207020         0.0       0.0          1.0       0.0   \n",
            "\n",
            "   Pclass_2  Pclass_3  \n",
            "0       0.0       0.0  \n",
            "1       1.0       0.0  \n",
            "2       0.0       0.0  \n",
            "3       0.0       1.0  \n",
            "4       1.0       0.0  \n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Age': [25, np.nan, 30, 22, np.nan],\n",
        "    'Fare': [100, 150, 75, 200, 50],\n",
        "    'Sex': ['female', 'male', 'male', 'female', np.nan],\n",
        "    'Pclass': [1, 2, 1, 3, 2]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the columns\n",
        "numeric_features = ['Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Pclass']\n",
        "\n",
        "# Create a preprocessing pipeline\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
        "    ('scaler', StandardScaler())                  # Scale numeric data\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Impute missing with 'missing' value\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))                     # One-Hot encode categorical data\n",
        "])\n",
        "\n",
        "# Combine preprocessing for numeric and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline, numeric_features),\n",
        "        ('cat', categorical_pipeline, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fit and transform the data\n",
        "X_processed = preprocessor.fit_transform(df)\n",
        "\n",
        "# Create a DataFrame with the processed data\n",
        "# Optionally, you can convert the result back to a DataFrame if needed\n",
        "processed_columns = (\n",
        "    [f'Age_scaled', 'Fare_scaled'] +\n",
        "    list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
        ")\n",
        "\n",
        "df_processed = pd.DataFrame(X_processed, columns=processed_columns)\n",
        "\n",
        "# Display the processed DataFrame\n",
        "print(\"Processed DataFrame:\")\n",
        "print(df_processed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OY1jI5IaIB"
      },
      "source": [
        "## Section 6: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBCcr3RIi-8"
      },
      "source": [
        "### **Task 6**: Create a New Feature\n",
        "\n",
        "*Instruction*: Create a new feature `FamilySize` = `Siblings/Spouses Aboard` + `Parents/Children Aboard` + 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gSza6VScIakN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275efd3c-5517-4678-c261-5d7009d9b735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed DataFrame:\n",
            "   FamilySize_scaled  Age_scaled  Fare_scaled  Sex_female  Sex_male  Pclass_1  \\\n",
            "0          -0.816497   -1.186295    -1.102568         1.0       0.0       1.0   \n",
            "1          -0.816497    0.122720     1.458030         0.0       1.0       0.0   \n",
            "2           1.224745    0.000000    -1.070848         1.0       0.0       1.0   \n",
            "3           1.224745   -0.695414     0.715385         0.0       1.0       0.0   \n",
            "4          -0.816497    1.758989     0.000000         1.0       0.0       0.0   \n",
            "\n",
            "   Pclass_2  Pclass_3  \n",
            "0       0.0       0.0  \n",
            "1       0.0       1.0  \n",
            "2       0.0       0.0  \n",
            "3       1.0       0.0  \n",
            "4       0.0       1.0  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Your code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Sample DataFrame with relevant columns\n",
        "data = {\n",
        "    'Siblings/Spouses Aboard': [1, 0, 2, 1, 0],\n",
        "    'Parents/Children Aboard': [0, 1, 0, 1, 1],\n",
        "    'Age': [22, 30, np.nan, 25, 40],\n",
        "    'Fare': [7.25, 71.83, 8.05, 53.10, np.nan],\n",
        "    'Sex': ['female', 'male', 'female', 'male', 'female'],\n",
        "    'Pclass': [1, 3, 1, 2, 3]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the new feature FamilySize\n",
        "df['FamilySize'] = df['Siblings/Spouses Aboard'] + df['Parents/Children Aboard'] + 1\n",
        "\n",
        "# Define the columns\n",
        "numeric_features = ['FamilySize', 'Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Pclass']\n",
        "\n",
        "# Create a preprocessing pipeline\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with the mean\n",
        "    ('scaler', StandardScaler())                  # Scale numeric data\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Impute missing with 'missing'\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))                     # One-Hot encode categorical data\n",
        "])\n",
        "\n",
        "# Combine preprocessing for numeric and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline, numeric_features),\n",
        "        ('cat', categorical_pipeline, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fit and transform the data\n",
        "X_processed = preprocessor.fit_transform(df)\n",
        "\n",
        "# Create a DataFrame with the processed data\n",
        "# Optionally, you can convert the result back to a DataFrame if needed\n",
        "feature_names = (\n",
        "    ['FamilySize_scaled', 'Age_scaled', 'Fare_scaled'] +\n",
        "    list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
        ")\n",
        "\n",
        "df_processed = pd.DataFrame(X_processed, columns=feature_names)\n",
        "\n",
        "# Display the processed DataFrame\n",
        "print(\"Processed DataFrame:\")\n",
        "print(df_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}